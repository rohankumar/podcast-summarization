{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6252eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/adl/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import transformers\n",
    "import tqdm\n",
    "import torch\n",
    "from reformer_pytorch import ReformerEncDec\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fbb7bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = \"../data/cleaned/train_clean.csv\"\n",
    "val_data = \"../data/cleaned/dev_clean.csv\"\n",
    "test_data = \"../data/cleaned/test_clean.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ddbeece",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_data)\n",
    "df_val = pd.read_csv(val_data)\n",
    "df_test = pd.read_csv(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08e29e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>episode_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>welcome to medicus a student run podcast about...</td>\n",
       "      <td>in this episode we sat down with a third year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey what is up everybody and welcome back to t...</td>\n",
       "      <td>we are so excited to be back with you guys wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good morning my people i ll be going well in t...</td>\n",
       "      <td>can animals reduce stress or increase it i hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is christy mathewson part of the texas a ...</td>\n",
       "      <td>surgery for biliary tract disease is among the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>welcome to episode number 2 of the av a moveme...</td>\n",
       "      <td>in this second episode of the podcast our co h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          transcript  \\\n",
       "0  welcome to medicus a student run podcast about...   \n",
       "1  hey what is up everybody and welcome back to t...   \n",
       "2  good morning my people i ll be going well in t...   \n",
       "3  this is christy mathewson part of the texas a ...   \n",
       "4  welcome to episode number 2 of the av a moveme...   \n",
       "\n",
       "                                 episode_description  \n",
       "0  in this episode we sat down with a third year ...  \n",
       "1  we are so excited to be back with you guys wit...  \n",
       "2  can animals reduce stress or increase it i hav...  \n",
       "3  surgery for biliary tract disease is among the...  \n",
       "4  in this second episode of the podcast our co h...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c07084c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>episode_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what s up you guys it s telling and ashley wit...</td>\n",
       "      <td>ashley and dallin discuss different approaches...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>three two one and stop popping step podcast th...</td>\n",
       "      <td>today puff and steph talk about looking out fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you want to go all the content you can yeah ex...</td>\n",
       "      <td>what do aegee skopje aegee bratislava aegee ky...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i m talking about today five nights at freddy ...</td>\n",
       "      <td>finally 2 years since it has been revealed her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hey good morning good afternoon and good eveni...</td>\n",
       "      <td>explicit language included for your benefit we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          transcript  \\\n",
       "0  what s up you guys it s telling and ashley wit...   \n",
       "1  three two one and stop popping step podcast th...   \n",
       "2  you want to go all the content you can yeah ex...   \n",
       "3  i m talking about today five nights at freddy ...   \n",
       "4  hey good morning good afternoon and good eveni...   \n",
       "\n",
       "                                 episode_description  \n",
       "0  ashley and dallin discuss different approaches...  \n",
       "1  today puff and steph talk about looking out fo...  \n",
       "2  what do aegee skopje aegee bratislava aegee ky...  \n",
       "3  finally 2 years since it has been revealed her...  \n",
       "4  explicit language included for your benefit we...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c84cecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>episode_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>welcome back to another episode of tuxedo time...</td>\n",
       "      <td>today on the podcast we go on a journey we tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what s up guys this episode of the podcast is ...</td>\n",
       "      <td>ever wanted a podcast from your three favorite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you are listening to irish illustrate insider ...</td>\n",
       "      <td>the irish illustrated insider crew discusses n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you have tuned into irish illustrated insider ...</td>\n",
       "      <td>irish illustrated insider tackles nfl combine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what s up everybody welcome to the in the dome...</td>\n",
       "      <td>breaking down a classic calgary flames comebac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          transcript  \\\n",
       "0  welcome back to another episode of tuxedo time...   \n",
       "1  what s up guys this episode of the podcast is ...   \n",
       "2  you are listening to irish illustrate insider ...   \n",
       "3  you have tuned into irish illustrated insider ...   \n",
       "4  what s up everybody welcome to the in the dome...   \n",
       "\n",
       "                                 episode_description  \n",
       "0  today on the podcast we go on a journey we tal...  \n",
       "1  ever wanted a podcast from your three favorite...  \n",
       "2  the irish illustrated insider crew discusses n...  \n",
       "3  irish illustrated insider tackles nfl combine ...  \n",
       "4  breaking down a classic calgary flames comebac...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc51016c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training data:  52396\n",
      "Length of validation data:  2183\n",
      "Length of test data:  1025\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of training data: \", len(df_train))\n",
    "print(\"Length of validation data: \", len(df_val))\n",
    "print(\"Length of test data: \", len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ec798f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the data\n",
    "word_freq = defaultdict(int)\n",
    "word_freq['PAD'] = 0\n",
    "i = 1\n",
    "for idx, row in df_train.iterrows():\n",
    "    transcript = row['transcript'].split(\" \")\n",
    "    for word in transcript:\n",
    "        if word not in word_freq:\n",
    "            word_freq[word]= i\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f234daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146002"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cb3f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq[\"unk\"] = 146002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12f9678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(text):\n",
    "    max_size = 4096\n",
    "    tokens = []\n",
    "    for word in text[:4096]:\n",
    "        if word in word_freq:\n",
    "            tokens.append(word_freq[word])\n",
    "        else:\n",
    "            tokens.append(word_freq['unk'])\n",
    "    if len(tokens)<4096:\n",
    "        for i in range(len(tokens), 4096):\n",
    "            tokens.append(word_freq['PAD'])\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0033974",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['transcript'] = df_train['transcript'].apply(tokenize_data)\n",
    "df_val['transcript'] = df_val['transcript'].apply(tokenize_data)\n",
    "df_test['transcript'] = df_test['transcript'].apply(tokenize_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f4dfe0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>episode_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2776, 1856, 6535, 3096, 1957, 76, 1856, 14600...</td>\n",
       "      <td>in this episode we sat down with a third year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3055, 1856, 2024, 146002, 2776, 3055, 4, 81, ...</td>\n",
       "      <td>we are so excited to be back with you guys wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2157, 1957, 1957, 259, 146002, 76, 1957, 954,...</td>\n",
       "      <td>can animals reduce stress or increase it i hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[81, 3055, 63, 203, 146002, 63, 203, 146002, 3...</td>\n",
       "      <td>surgery for biliary tract disease is among the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2776, 1856, 6535, 3096, 1957, 76, 1856, 14600...</td>\n",
       "      <td>in this second episode of the podcast our co h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52391</th>\n",
       "      <td>[2024, 1957, 391, 146002, 4, 954, 1856, 146002...</td>\n",
       "      <td>omg may sex video ka most probably the first r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52392</th>\n",
       "      <td>[3055, 1856, 6535, 6535, 1957, 146002, 1856, 1...</td>\n",
       "      <td>where have i been and why i haven t done podca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52393</th>\n",
       "      <td>[2776, 1957, 2776, 146002, 2776, 1856, 146002,...</td>\n",
       "      <td>blake webber and steve welcome guest and world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52394</th>\n",
       "      <td>[2776, 1856, 146002, 2776, 1957, 391, 6535, 25...</td>\n",
       "      <td>once again we welcome becky to our podcast tod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52395</th>\n",
       "      <td>[3055, 1856, 2024, 146002, 2157, 391, 2024, 20...</td>\n",
       "      <td>community seasons 1 2 writer andrew guest join...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52396 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              transcript  \\\n",
       "0      [2776, 1856, 6535, 3096, 1957, 76, 1856, 14600...   \n",
       "1      [3055, 1856, 2024, 146002, 2776, 3055, 4, 81, ...   \n",
       "2      [2157, 1957, 1957, 259, 146002, 76, 1957, 954,...   \n",
       "3      [81, 3055, 63, 203, 146002, 63, 203, 146002, 3...   \n",
       "4      [2776, 1856, 6535, 3096, 1957, 76, 1856, 14600...   \n",
       "...                                                  ...   \n",
       "52391  [2024, 1957, 391, 146002, 4, 954, 1856, 146002...   \n",
       "52392  [3055, 1856, 6535, 6535, 1957, 146002, 1856, 1...   \n",
       "52393  [2776, 1957, 2776, 146002, 2776, 1856, 146002,...   \n",
       "52394  [2776, 1856, 146002, 2776, 1957, 391, 6535, 25...   \n",
       "52395  [3055, 1856, 2024, 146002, 2157, 391, 2024, 20...   \n",
       "\n",
       "                                     episode_description  \n",
       "0      in this episode we sat down with a third year ...  \n",
       "1      we are so excited to be back with you guys wit...  \n",
       "2      can animals reduce stress or increase it i hav...  \n",
       "3      surgery for biliary tract disease is among the...  \n",
       "4      in this second episode of the podcast our co h...  \n",
       "...                                                  ...  \n",
       "52391  omg may sex video ka most probably the first r...  \n",
       "52392  where have i been and why i haven t done podca...  \n",
       "52393  blake webber and steve welcome guest and world...  \n",
       "52394  once again we welcome becky to our podcast tod...  \n",
       "52395  community seasons 1 2 writer andrew guest join...  \n",
       "\n",
       "[52396 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d08d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna()\n",
    "df_test = df_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ae64e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(text):\n",
    "    max_size = 4096\n",
    "    tokens = []\n",
    "    for word in text[:4096]:\n",
    "        if word in word_freq:\n",
    "            tokens.append(word_freq[word])\n",
    "        else:\n",
    "            tokens.append(word_freq['unk'])\n",
    "    if len(tokens)<1024:\n",
    "        for i in range(len(tokens), 4096):\n",
    "            tokens.append(word_freq['PAD'])\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff217162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11782/1643322906.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['episode_description'] = df_train['episode_description'].apply(tokenize_data)\n"
     ]
    }
   ],
   "source": [
    "df_train['episode_description'] = df_train['episode_description'].apply(tokenize_data)\n",
    "df_val['episode_description'] = df_val['episode_description'].apply(tokenize_data)\n",
    "df_test['episode_description'] = df_test['episode_description'].apply(tokenize_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c2fe457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>episode_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2776, 1856, 6535, 3096, 1957, 76, 1856, 14600...</td>\n",
       "      <td>[63, 4637, 146002, 81, 3055, 63, 203, 146002, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3055, 1856, 2024, 146002, 2776, 3055, 4, 81, ...</td>\n",
       "      <td>[2776, 1856, 146002, 4, 954, 1856, 146002, 203...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2157, 1957, 1957, 259, 146002, 76, 1957, 954,...</td>\n",
       "      <td>[3096, 4, 4637, 146002, 4, 4637, 63, 76, 4, 65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[81, 3055, 63, 203, 146002, 63, 203, 146002, 3...</td>\n",
       "      <td>[203, 391, 954, 2157, 1856, 954, 2024, 146002,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2776, 1856, 6535, 3096, 1957, 76, 1856, 14600...</td>\n",
       "      <td>[63, 4637, 146002, 81, 3055, 63, 203, 146002, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          transcript  \\\n",
       "0  [2776, 1856, 6535, 3096, 1957, 76, 1856, 14600...   \n",
       "1  [3055, 1856, 2024, 146002, 2776, 3055, 4, 81, ...   \n",
       "2  [2157, 1957, 1957, 259, 146002, 76, 1957, 954,...   \n",
       "3  [81, 3055, 63, 203, 146002, 63, 203, 146002, 3...   \n",
       "4  [2776, 1856, 6535, 3096, 1957, 76, 1856, 14600...   \n",
       "\n",
       "                                 episode_description  \n",
       "0  [63, 4637, 146002, 81, 3055, 63, 203, 146002, ...  \n",
       "1  [2776, 1856, 146002, 4, 954, 1856, 146002, 203...  \n",
       "2  [3096, 4, 4637, 146002, 4, 4637, 63, 76, 4, 65...  \n",
       "3  [203, 391, 954, 2157, 1856, 954, 2024, 146002,...  \n",
       "4  [63, 4637, 146002, 81, 3055, 63, 203, 146002, ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24cc389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = torch.empty((len(df_train), 4096))\n",
    "for i,row in enumerate(df_train['transcript']):\n",
    "    train_doc[i] = torch.tensor(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55beada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69484d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52381, 4096])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f7643a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sum = torch.empty((len(train_doc), 4096))\n",
    "for i,row in enumerate(df_train['episode_description']):\n",
    "    train_sum[i] = torch.tensor(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3667d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sum.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58a588e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52381, 4096])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc2b1881",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m DE_SEQ_LEN \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4096\u001b[39m\n\u001b[1;32m      5\u001b[0m EN_SEQ_LEN \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4096\u001b[39m\n\u001b[0;32m----> 7\u001b[0m enc_dec \u001b[38;5;241m=\u001b[39m \u001b[43mReformerEncDec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43menc_num_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m146003\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43menc_depth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43menc_max_seq_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDE_SEQ_LEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdec_num_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m146003\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdec_depth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdec_max_seq_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEN_SEQ_LEN\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# train_seq_in = torch.randint(0, 20000, (2, DE_SEQ_LEN)).long()\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# train_seq_out = torch.randint(0, 20000, (2, EN_SEQ_LEN)).long()\u001b[39;00m\n\u001b[1;32m     19\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/adl/lib/python3.9/site-packages/torch/nn/modules/module.py:688\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 688\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/adl/lib/python3.9/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/adl/lib/python3.9/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 578 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/adl/lib/python3.9/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/adl/lib/python3.9/site-packages/torch/nn/modules/module.py:601\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 601\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/anaconda3/envs/adl/lib/python3.9/site-packages/torch/nn/modules/module.py:688\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 688\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from reformer_pytorch import ReformerEncDec\n",
    "\n",
    "DE_SEQ_LEN = 4096\n",
    "EN_SEQ_LEN = 4096\n",
    "\n",
    "enc_dec = ReformerEncDec(\n",
    "    dim = 512,\n",
    "    enc_num_tokens = 146003,\n",
    "    enc_depth = 6,\n",
    "    enc_max_seq_len = DE_SEQ_LEN,\n",
    "    dec_num_tokens = 146003,\n",
    "    dec_depth = 6,\n",
    "    dec_max_seq_len = EN_SEQ_LEN\n",
    ").cuda()\n",
    "\n",
    "# train_seq_in = torch.randint(0, 20000, (2, DE_SEQ_LEN)).long()\n",
    "# train_seq_out = torch.randint(0, 20000, (2, EN_SEQ_LEN)).long()\n",
    "batch_size = 32\n",
    "for i in range(0,len(train_doc), batch_size):\n",
    "    doc = train_doc[i:i+batch_size]\n",
    "    summ = train_sum[i:i+batch_size]\n",
    "    train_seq_in = doc.long().cuda()\n",
    "    train_seq_out = summ.long().cuda()\n",
    "    print(train_seq_in.shape)\n",
    "    print(train_seq_out.shape)\n",
    "    input_mask = torch.ones(len(doc), DE_SEQ_LEN).bool().cuda()\n",
    "\n",
    "    loss = enc_dec(train_seq_in, train_seq_out, return_loss = True, enc_input_mask = input_mask)\n",
    "    print(\"Loss: \", loss)\n",
    "    loss.backward()\n",
    "# # learn\n",
    "\n",
    "# # evaluate with the following\n",
    "# eval_seq_in = torch.randint(0, 20000, (1, DE_SEQ_LEN)).long().cuda()\n",
    "# eval_seq_out_start = torch.tensor([[0.]]).long().cuda() # assume 0 is id of start token\n",
    "# samples = enc_dec.generate(eval_seq_in, eval_seq_out_start, seq_len = EN_SEQ_LEN, eos_token = 1) # assume 1 is id of stop token\n",
    "# print(samples.shape) # (1, <= 1024) decode the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9d372a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_adl)",
   "language": "python",
   "name": "conda_adl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
